{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _future_ import division\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def detectFaceOpenCVDnn(net, frame):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes\n",
    "\n",
    "if _name_ == \"__main__\" :\n",
    "\n",
    "    # OpenCV DNN supports 2 networks.\n",
    "    # 1. FP16 version of the original caffe implementation ( 5.4 MB )\n",
    "    # 2. 8 bit Quantized version using Tensorflow ( 2.7 MB )\n",
    "    DNN = \"CAFFE\"\n",
    "    if DNN == \"CAFFE\":\n",
    "        modelFile = os.path.join(\"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "        configFile = os.path.join(\"deploy.prototxt\")\n",
    "        net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "    else:\n",
    "        modelFile = os.path.join(\"opencv_face_detector_uint8.pb\")\n",
    "        print(modelFile)\n",
    "        configFile = os.path.join(\"opencv_face_detector.pbtxt\")\n",
    "        print(configFile)\n",
    "        net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "\n",
    "    conf_threshold = 0.7\n",
    "\n",
    "    source = 0\n",
    "    if len(sys.argv) > 1:\n",
    "        source = sys.argv[1]\n",
    "\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    hasFrame, frame = cap.read()\n",
    "\n",
    "    vid_writer = cv2.VideoWriter('output-dnn-{}.avi'.format(str(source).split(\".\")[0]),cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1],frame.shape[0]))\n",
    "\n",
    "    frame_count = 0\n",
    "    tt_opencvDnn = 0\n",
    "    while(1):\n",
    "        hasFrame, frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            break\n",
    "        frame_count += 1\n",
    "\n",
    "        t = time.time()\n",
    "        outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,frame)\n",
    "        tt_opencvDnn += time.time() - t\n",
    "        fpsOpencvDnn = frame_count / tt_opencvDnn\n",
    "        label = \"OpenCV DNN ; FPS : {:.2f}\".format(fpsOpencvDnn)\n",
    "        cv2.putText(outOpencvDnn, label, (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"Face Detection Comparison\", outOpencvDnn)\n",
    "\n",
    "        vid_writer.write(outOpencvDnn)\n",
    "        if frame_count == 1:\n",
    "            tt_opencvDnn = 0\n",
    "\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    vid_writer.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
